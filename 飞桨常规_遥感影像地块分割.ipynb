{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 飞桨常规赛：遥感影像地块分割8月第1名方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 环境准备\n",
    "本项目采用paddleseg套件实现了遥感影像地块的分割，paddleseg版本号为v2.1版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 下载paddlesegv2.1版本\r\n",
    "!git clone -b release/2.1 https://gitee.com/paddlepaddle/PaddleSeg.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据集准备和分析\n",
    "首先将数据集解压缩，然后运行work目录下的make_data_list.py划分出训练集和验证集文件列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 解压训练数据集到work目录下\r\n",
    "!unzip -oq -d /home/aistudio/work /home/aistudio/data/data80164/train_and_label.zip\r\n",
    "# 解压测试数据集到work目录下\r\n",
    "!unzip -oq -d /home/aistudio/work /home/aistudio/data/data80164/img_test.zip\r\n",
    "# 生成文件列表文件\r\n",
    "!python /home/aistudio/work/make_data_list.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 分析数据集\n",
    "数据集的分析参考了参考链接中的分析方法，统计了数据中四种类型的面积分布情况。但实际本方案并没有针对分析后的数据集做特定的优化，后续会继续尝试参考链接中的思路。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "NUM_CLASSES = 4\r\n",
    "\r\n",
    "area = {i : 0 for i in range(NUM_CLASSES)}\r\n",
    "area_proportion = {i : {0 : 0, 1 : 0, 2 : 0, 3 : 0} for i in range(NUM_CLASSES)}\r\n",
    "area[255] = 0\r\n",
    "image_num = 0\r\n",
    "\r\n",
    "def calc(image, num_classes=NUM_CLASSES):\r\n",
    "    label_image = np.array(image)\r\n",
    "    for cls in range(num_classes):\r\n",
    "        area[cls] += np.count_nonzero(label_image == cls)\r\n",
    "    area[255] += np.count_nonzero(label_image == 255)\r\n",
    "\r\n",
    "def area_calc(image, num_classes=NUM_CLASSES):\r\n",
    "    label_image = np.array(image)\r\n",
    "    image_area = label_image.shape[0] * label_image.shape[1]\r\n",
    "    for cls in range(num_classes):\r\n",
    "        proportion = np.count_nonzero(label_image == cls) / float(image_area)\r\n",
    "        if proportion < 0.01:\r\n",
    "            area_proportion[cls][0] += 1\r\n",
    "        elif proportion < 0.02:\r\n",
    "            area_proportion[cls][1] += 1\r\n",
    "        elif proportion < 0.8:\r\n",
    "            area_proportion[cls][2] += 1\r\n",
    "        else:\r\n",
    "            area_proportion[cls][3] += 1\r\n",
    "\r\n",
    "\r\n",
    "# 统计四种类型的面积占比\r\n",
    "train_file_dir = '/home/aistudio/work/train_list.txt'\r\n",
    "val_file_dir = '/home/aistudio/work/val_list.txt'\r\n",
    "with open(train_file_dir, 'r') as f:\r\n",
    "    for line in f.readlines():\r\n",
    "        label_dir = line.split()[1]\r\n",
    "        # print(label_dir)\r\n",
    "        image_label = cv2.imread(label_dir, cv2.IMREAD_GRAYSCALE)\r\n",
    "        calc(image_label)\r\n",
    "        area_calc(image_label)\r\n",
    "        image_num += 1\r\n",
    "        # break\r\n",
    "\r\n",
    "for cls in range(NUM_CLASSES):\r\n",
    "    area[cls] = area[cls] / (image_num * 256.0 * 256.0)\r\n",
    "area[255] = area[255] / (image_num * 256.0 * 256.0)\r\n",
    "print(area)\r\n",
    "print(area_proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据集代码准备\n",
    "模型训练借助了paddleseg套件，在paddleseg中新加入了一种数据集RemoteSensing。本方案新加入数据集的思路实际上是为后续模型持续优化做准备，目前已实现的方案并没有对数据集做特别的处理，下面简述新加数据集时涉及到的修改padddleseg源码步骤\n",
    "1. 在work/PaddleSeg/paddleseg/datasets中添加python文件remote_sensing.py\n",
    "2. 修改work/PaddleSeg/paddleseg/datasets中的__init__.py，添加一句话from .remote_sensing import RemoteSensing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型训练\n",
    "从数据集分析结果来看，各个类别像素占整个图片的面积比例很小，所以选择了参考链接[1]中的ocrnet+hrnet模型，在训练时分了两个阶段，第一个阶段的loss采用了CrossEntropyLoss，训练了大约30个epoch，第二阶段采用的loss为CrossEntropyLoss + LovaszSoftmaxLoss，训练了大约10个epoch。两阶段训练的思路参考了paddleseg的loss说明https://gitee.com/paddlepaddle/PaddleSeg/blob/release/2.1/docs/module/loss/lovasz_loss.md\n",
    "\n",
    "在训练前，将make_data_list.py产生的文件列表放在/home/aistudio/work/multi_class_datalist目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 调用paddleseg进行模型训练前30个epoch\r\n",
    "!python /home/aistudio/work/PaddleSeg/train.py \\\r\n",
    "       --config /home/aistudio/work/PaddleSeg/configs/quick_start/ocrnet_hrnet_256x256_ce.yml \\\r\n",
    "       --do_eval \\\r\n",
    "       --use_vdl \\\r\n",
    "       --save_interval 5000 \\\r\n",
    "       --save_dir output_ocrnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 调用paddleseg进行模型训练后10个epoch，在前30个epoch的基础上继续训练\r\n",
    "!python /home/aistudio/work/PaddleSeg/train.py \\\r\n",
    "       --config /home/aistudio/work/PaddleSeg/configs/quick_start/ocrnet_hrnet_256x256_ce_and_lovasz.yml \\\r\n",
    "       --do_eval \\\r\n",
    "       --use_vdl \\\r\n",
    "       --save_interval 5000 \\\r\n",
    "       --resume_model /home/aistudio/output_ocrnet/iter_160000 \\\r\n",
    "       --save_dir output_ocrnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型预测\n",
    "模型预测时希望将预测的结果直接作为提交结果，但是paddleseg默认预测的结果是增加权重后生成的图片，所以对paddleseg的源码进行了修改。修改的文件为work/PaddleSeg/paddleseg/core/predict.py，修改后是下面这段代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 修改predict函数\r\n",
    "def predict(model,\r\n",
    "            model_path,\r\n",
    "            transforms,\r\n",
    "            image_list,\r\n",
    "            image_dir=None,\r\n",
    "            save_dir='output',\r\n",
    "            aug_pred=False,\r\n",
    "            scales=1.0,\r\n",
    "            flip_horizontal=True,\r\n",
    "            flip_vertical=False,\r\n",
    "            is_slide=False,\r\n",
    "            stride=None,\r\n",
    "            crop_size=None):\r\n",
    "    \"\"\"\r\n",
    "    predict and visualize the image_list.\r\n",
    "\r\n",
    "    Args:\r\n",
    "        model (nn.Layer): Used to predict for input image.\r\n",
    "        model_path (str): The path of pretrained model.\r\n",
    "        transforms (transform.Compose): Preprocess for input image.\r\n",
    "        image_list (list): A list of image path to be predicted.\r\n",
    "        image_dir (str, optional): The root directory of the images predicted. Default: None.\r\n",
    "        save_dir (str, optional): The directory to save the visualized results. Default: 'output'.\r\n",
    "        aug_pred (bool, optional): Whether to use mulit-scales and flip augment for predition. Default: False.\r\n",
    "        scales (list|float, optional): Scales for augment. It is valid when `aug_pred` is True. Default: 1.0.\r\n",
    "        flip_horizontal (bool, optional): Whether to use flip horizontally augment. It is valid when `aug_pred` is True. Default: True.\r\n",
    "        flip_vertical (bool, optional): Whether to use flip vertically augment. It is valid when `aug_pred` is True. Default: False.\r\n",
    "        is_slide (bool, optional): Whether to predict by sliding window. Default: False.\r\n",
    "        stride (tuple|list, optional): The stride of sliding window, the first is width and the second is height.\r\n",
    "            It should be provided when `is_slide` is True.\r\n",
    "        crop_size (tuple|list, optional):  The crop size of sliding window, the first is width and the second is height.\r\n",
    "            It should be provided when `is_slide` is True.\r\n",
    "\r\n",
    "    \"\"\"\r\n",
    "    utils.utils.load_entire_model(model, model_path)\r\n",
    "    model.eval()\r\n",
    "    nranks = paddle.distributed.get_world_size()\r\n",
    "    local_rank = paddle.distributed.get_rank()\r\n",
    "    if nranks > 1:\r\n",
    "        img_lists = partition_list(image_list, nranks)\r\n",
    "    else:\r\n",
    "        img_lists = [image_list]\r\n",
    "\r\n",
    "    added_saved_dir = os.path.join(save_dir, 'added_prediction')\r\n",
    "    pred_saved_dir = os.path.join(save_dir, 'pseudo_color_prediction')\r\n",
    "\r\n",
    "    logger.info(\"Start to predict...\")\r\n",
    "    progbar_pred = progbar.Progbar(target=len(img_lists[0]), verbose=1)\r\n",
    "    with paddle.no_grad():\r\n",
    "        for i, im_path in enumerate(img_lists[local_rank]):\r\n",
    "            im = cv2.imread(im_path)\r\n",
    "            ori_shape = im.shape[:2]\r\n",
    "            im, _ = transforms(im)\r\n",
    "            im = im[np.newaxis, ...]\r\n",
    "            im = paddle.to_tensor(im)\r\n",
    "\r\n",
    "            if aug_pred:\r\n",
    "                pred = infer.aug_inference(\r\n",
    "                    model,\r\n",
    "                    im,\r\n",
    "                    ori_shape=ori_shape,\r\n",
    "                    transforms=transforms.transforms,\r\n",
    "                    scales=scales,\r\n",
    "                    flip_horizontal=flip_horizontal,\r\n",
    "                    flip_vertical=flip_vertical,\r\n",
    "                    is_slide=is_slide,\r\n",
    "                    stride=stride,\r\n",
    "                    crop_size=crop_size)\r\n",
    "            else:\r\n",
    "                pred = infer.inference(\r\n",
    "                    model,\r\n",
    "                    im,\r\n",
    "                    ori_shape=ori_shape,\r\n",
    "                    transforms=transforms.transforms,\r\n",
    "                    is_slide=is_slide,\r\n",
    "                    stride=stride,\r\n",
    "                    crop_size=crop_size)\r\n",
    "            pred = paddle.squeeze(pred)\r\n",
    "            pred = pred.numpy().astype('uint8')\r\n",
    "\r\n",
    "            # get the saved name\r\n",
    "            if image_dir is not None:\r\n",
    "                im_file = im_path.replace(image_dir, '')\r\n",
    "            else:\r\n",
    "                im_file = os.path.basename(im_path)\r\n",
    "            if im_file[0] == '/' or im_file[0] == '\\\\':\r\n",
    "                im_file = im_file[1:]\r\n",
    "\r\n",
    "            # 修改预测后的图片\r\n",
    "            pred_saved_path = os.path.join(save_dir, im_file.rsplit(\".\")[0] + \".png\")\r\n",
    "            mkdir(pred_saved_path)\r\n",
    "            cv2.imwrite(pred_saved_path, pred)\r\n",
    "\r\n",
    "            progbar_pred.update(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 模型预测\r\n",
    "!python /home/aistudio/work/PaddleSeg/predict.py \\\r\n",
    "       --config /home/aistudio/work/PaddleSeg/configs/quick_start/ocrnet_hrnet_256x256_ce_and_lovasz.yml \\\r\n",
    "       --model_path /home/aistudio/output_ocrnet/iter_200000/model.pdparams \\\r\n",
    "       --image_path /home/aistudio/work/img_testA \\\r\n",
    "       --save_dir /home/aistudio/work/result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 参考链接\n",
    "https://zhuanlan.zhihu.com/p/346862877"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 2.1.2 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
